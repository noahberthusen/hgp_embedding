{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from itertools import chain, combinations\n",
    "from scipy import sparse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# configuration model\n",
    "# https://en.wikipedia.org/wiki/Configuration_model\n",
    "\n",
    "n = 16\n",
    "deg_v = 3 # w_c. Every bit is in this many checks\n",
    "deg_c = 4 # w_r. Every check has this many bits in it\n",
    "num_checks = (n*deg_v)//deg_c\n",
    "k = n - num_checks\n",
    "\n",
    "vs = np.array([[j for i in range(deg_v)] for j in range(n)]).flatten()\n",
    "cs = np.array([[j for i in range(deg_c)] for j in range(num_checks)]).flatten()\n",
    "\n",
    "H = np.zeros((num_checks, n), dtype=bool)\n",
    "\n",
    "while (vs.size and cs.size):\n",
    "    # choose random 'stub' from each array\n",
    "    double_edge = True\n",
    "    while(double_edge):\n",
    "        v_ind = np.random.randint(0, len(vs))\n",
    "        c_ind = np.random.randint(0, len(cs))\n",
    "\n",
    "        if (H[cs[c_ind]][vs[v_ind]] != 1):\n",
    "            double_edge = False\n",
    "            H[cs[c_ind]][vs[v_ind]] = 1\n",
    "            vs = np.delete(vs, v_ind)\n",
    "            cs =np.delete(cs, c_ind)\n",
    "\n",
    "H = sparse.csc_matrix(H)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from classical_code import *\n",
    "\n",
    "write_code('./ldpc_codes/16_12_3_4.txt', )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class HypergraphProduct(object):\n",
    "    def __init__(self, H):\n",
    "        hx1 = sparse.kron(H, np.eye(H.shape[1], dtype=bool))\n",
    "        hx2 = sparse.kron(np.eye(H.shape[0], dtype=bool), H.T)\n",
    "        self.Hx = sparse.csr_matrix(sparse.hstack([hx1, hx2]))\n",
    "\n",
    "        hz1 = sparse.kron(np.eye(H.shape[1], dtype=bool), H)\n",
    "        hz2 = sparse.kron(H.T, np.eye(H.shape[0], dtype=bool))\n",
    "        self.Hz = sparse.csr_matrix(sparse.hstack([hz1, hz2]))\n",
    "\n",
    "        self.n = self.Hx.shape[1]\n",
    "        self.k = self.Hx.shape[0]\n",
    "        self.stabilizers = set(np.arange(self.k))\n",
    "\n",
    "        self.Fx = np.array([list(powerset(self.Hx[i].indices))[1:] for i in range(self.k)], dtype=object)\n",
    "        self.Fz = np.array([list(powerset(self.Hz[i].indices))[1:] for i in range(self.k)], dtype=object)\n",
    "\n",
    "        self.sigma_Fx = np.array([[syn_from_F(g, self.Hz) for g in F] for F in self.Fx], dtype=object)\n",
    "        self.sigma_Fz = np.array([[syn_from_F(g, self.Hx) for g in F] for F in self.Fz], dtype=object)\n",
    "\n",
    "    def remove_stabilizers(self, indices=None, num=None):\n",
    "        if (num):\n",
    "            indices = set(np.random.choice(self.k, num, replace=False))\n",
    "        indices = list(self.stabilizers ^ indices)\n",
    "\n",
    "        return (self.Hx[indices], self.Hz[indices], \n",
    "            self.Fx[indices].flatten(), self.Fz[indices].flatten(), \n",
    "            self.sigma_Fx[indices].flatten(), self.sigma_Fz[indices].flatten())\n",
    "\n",
    "    def get_all(self):\n",
    "        return (self.Hx, self.Hz, self.Fx.flatten(), self.Fz.flatten(), self.sigma_Fx.flatten(), self.sigma_Fz.flatten())\n",
    "\n",
    "    def powerset(iterable):\n",
    "        s = list(iterable)\n",
    "        return chain.from_iterable(combinations(s, r) for r in range(len(s)+1))\n",
    "\n",
    "    def syn_from_F(F, H):\n",
    "        eF = np.zeros(H.shape[1], dtype=bool)\n",
    "        np.put(eF, F, [1])\n",
    "        return set(np.where(H.dot(eF) % 2)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "hx1 = sparse.kron(H, np.eye(H.shape[1], dtype=bool))\n",
    "hx2 = sparse.kron(np.eye(H.shape[0], dtype=bool), H.T)\n",
    "Hx = sparse.csr_matrix(sparse.hstack([hx1, hx2], ))\n",
    "\n",
    "hz1 = sparse.kron(np.eye(H.shape[1], dtype=bool), H)\n",
    "hz2 = sparse.kron(H.T, np.eye(H.shape[0], dtype=bool))\n",
    "Hz = sparse.csr_matrix(sparse.hstack([hz1, hz2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "24576"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "2**Hx[0].nnz*Hx.shape[0] # number of error syndromes we have to check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def powerset(iterable):\n",
    "    s = list(iterable)\n",
    "    return chain.from_iterable(combinations(s, r) for r in range(len(s)+1))\n",
    "\n",
    "def syn_from_F(F, H):\n",
    "    eF = np.zeros(Hx.shape[1], dtype=bool)\n",
    "    np.put(eF, F, [True])\n",
    "    return set(np.where(H.dot(eF) % 2)[0])\n",
    "\n",
    "Fx = [list(powerset(Hx[i].indices))[1:] for i in range(Hx.shape[0])]\n",
    "Fx = list(chain(*Fx)) # can take set of this list for slight reduction in size\n",
    "# Fx_coords = np.array([(item, i) for i, j in enumerate(Fx) for item in j])\n",
    "# Fx_arr = sparse.coo_matrix(([True for i in range(len(Fx_coords))], (Fx_coords[:,0], Fx_coords[:,1])), dtype=bool).tocsc()\n",
    "# sigma_Fx = (Hz.tocsc() @ Fx_arr).transpose()\n",
    "\n",
    "# Fx = [set(g) for g in Fx] \n",
    "Fz = [list(powerset(Hz[i].indices))[1:] for i in range(Hz.shape[0])]\n",
    "Fz = list(chain(*Fz))\n",
    "# Fz_coords = np.array([(item, i) for i, j in enumerate(Fz) for item in j])\n",
    "# Fz_arr = sparse.coo_matrix(([True for i in range(len(Fz_coords))], (Fz_coords[:,0], Fz_coords[:,1])), dtype=bool).tocsc()\n",
    "# sigma_Fz = (Hx.tocsc() @ Fz_arr).transpose()\n",
    "\n",
    "# Fz = [set(g) for g in Fz]\n",
    "\n",
    "sigma_Fx = [syn_from_F(g, Hz) for g in Fx] # set of indices where syndrome is 1\n",
    "sigma_Fz = [syn_from_F(g, Hx) for g in Fz]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ssf(syn, x_z):\n",
    "    # given a syndrome, syn: sigma_x or sigma_z \n",
    "    # x_z false for x stabilizers, true for z stabilizers\n",
    "    s = set(np.where(syn.copy())[0])\n",
    "    e = set()\n",
    "    F = Fx if x_z else Fz\n",
    "    sigma_F = sigma_Fx if x_z else sigma_Fz\n",
    "    \n",
    "    while True:\n",
    "        max = -1\n",
    "        max_gen = None\n",
    "        max_sigma_gen = None\n",
    "        for g, sigma_g in zip(F, sigma_F):\n",
    "            s_i = s ^ sigma_g\n",
    "            if (len(s_i) < len(s)):\n",
    "                rel_weight = (len(s) - len(s_i)) / len(g)\n",
    "                if (rel_weight > max):\n",
    "                    max = rel_weight\n",
    "                    max_gen = g\n",
    "                    max_sigma_gen = sigma_g\n",
    "            else:\n",
    "                continue\n",
    "\n",
    "        if (max == -1):\n",
    "            if (len(s) == 0):\n",
    "                return e\n",
    "            else:\n",
    "                return \"FAIL\"\n",
    "        else:\n",
    "            e = e ^ set(max_gen)\n",
    "            s = s ^ max_sigma_gen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hgp = HypergraphProduct(H)\n",
    "# Hx, Hz, Fx, Fz, sigma_Fx, sigma_Fz = hgp.remove_stabilizers(num=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = 0.01\n",
    "\n",
    "# how is this able to decode an error with more than (d-1)/2 errors?\n",
    "sum = 0\n",
    "\n",
    "for i in range(1):\n",
    "    eX = [1 if np.random.uniform() < p else 0 for i in range(Hx.shape[1])]\n",
    "    # eZ = [True if np.random.uniform() < p else False for i in range(Hz.shape[1])]\n",
    "    sigma_eX = Hx.dot(eX) % 2\n",
    "    # s = set(np.where(sigma_eX.copy())[0])\n",
    "    # sigma_eZ = np.dot(Hz, eZ)\n",
    "    e1 = ssf(sigma_eX, False)\n",
    "    # e2 = ssf(sigma_eZ, True)\n",
    "    if(e1 == set(np.where(eX)[0])):\n",
    "        sum += 1\n",
    "    # new_e = e1 ^ set(np.where(eX)[0])\n",
    "    # print(len(np.where(eX)[0]), len(np.where(eZ)[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1225 12\n",
      "1218 12\n",
      "0.93325230169843\n"
     ]
    }
   ],
   "source": [
    "from math import comb\n",
    "import math\n",
    "n = Hx.shape[1]\n",
    "delta_g = 7\n",
    "print(n, int(p*n))\n",
    "num_possible_errors = comb(n, int(p*n))\n",
    "print(n-delta_g, int(p*n))\n",
    "disjoint_errors = comb(n-delta_g, int(p*n))\n",
    "print(disjoint_errors/num_possible_errors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "36076d0e02b8d1858d0bd5b32bffaa710811761ccb670f476492e9c2dea26ac0"
  },
  "kernelspec": {
   "display_name": "Python 3.8.12 ('qc')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
